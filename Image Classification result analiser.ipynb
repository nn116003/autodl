{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a4996b875bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from utils.datasets import ImageFolderWithPath\n",
    "def mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル設定\n",
    "arch = \"resnet18\"\n",
    "num_classes = 37\n",
    "data_dir = \"./data\"\n",
    "batch_size = 256\n",
    "workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価用データに対して予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 読み込み\n",
    "model = models.__dict__[arch](num_classes = num_classes).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "checkpoint = torch.load(\"./model_best.pth.tar\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# データセット\n",
    "testdir = os.path.join(data_dir, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "test_dataset = ImageFolderWithPath(\n",
    "    testdir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True)\n",
    "\n",
    "# 予測\n",
    "hold_num = len(test_dataset)\n",
    "test_pred = torch.zeros(hold_num, num_classes)\n",
    "test_ans = torch.zeros(hold_num).long()\n",
    "test_path = []\n",
    "start_idx = 0\n",
    "for i, ((input, target), path) in enumerate(test_loader):\n",
    "    target = target.cuda(async=True)\n",
    "    input_var = torch.autograd.Variable(input, volatile=True)\n",
    "    target_var = torch.autograd.Variable(target, volatile=True)\n",
    "    \n",
    "    # compute output\n",
    "    output = model(input_var).data.cpu()\n",
    "    b_size = output.size(0)\n",
    "    test_pred[start_idx:(start_idx + b_size),:] = output\n",
    "    test_ans[start_idx:(start_idx + b_size)] = target\n",
    "    start_idx += b_size\n",
    "    test_path.extend(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans_path = pd.DataFrame({\"ans\":test_ans.numpy(), \"path\":test_path})\n",
    "#data = pd.concat((test_pred, ans_path), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測値および正解データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"latest_res.csv\")\n",
    "test_pred = pd.DataFrame(test_pred.numpy())\n",
    "ans_path = pd.DataFrame({\"ans\":test_ans.numpy(), \"path\":test_path})\n",
    "data = pd.concat((test_pred, ans_path), axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pred_lab\"] = data.iloc[:,:-2].values.argmax(axis=1)\n",
    "(data.pred_lab == data.ans).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測ラベルとクラス名対応表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ref = pd.read_csv(\"lab_ref.csv\")\n",
    "lab_ref_dict = {}\n",
    "for i in range(lab_ref.shape[0]):\n",
    "    lab_ref_dict[i] = lab_ref.name[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lab_ref.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_cat = pd.Categorical(data.ans.values, categories=np.arange(l).astype(int))\n",
    "pred_cat = pd.Categorical(data.iloc[:,:l].values.argmax(axis=1), categories=np.arange(l).astype(int))\n",
    "conf_mat = pd.crosstab(ans_cat, pred_cat) # ans * pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\",ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レポート用結果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir(\"./result\")\n",
    "lab_ref.sort_values(\"id\", inplace=True)\n",
    "# 予測値、結果データ\n",
    "scores = data.iloc[:,:lab_ref.shape[0]].values\n",
    "ex_scores = np.exp(scores)\n",
    "probs = ex_scores / ex_scores.sum(axis=1, keepdims=True)\n",
    "probs = pd.DataFrame(probs)\n",
    "probs.columns = lab_ref.name.values\n",
    "pred_results = pd.concat([probs, data[[\"ans\", \"path\",\"pred_lab\"]]], axis=1)\n",
    "pred_results.head()\n",
    "pred_results.to_csv(\"./result/prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 誤判別画像フォルダ\n",
    "mkdir(\"./result/fail_imgs\")\n",
    "data[\"correct\"] = data.ans == data.pred_lab\n",
    "fail_data = data.iloc[~data.correct.values,:]\n",
    "fail_data.reset_index(inplace=True)\n",
    "fail_data.head()\n",
    "for i in range(fail_data.shape[0]):\n",
    "    ans_lab = lab_ref_dict[fail_data.ans[i]]\n",
    "    output_dir = os.path.join(\"./result/fail_imgs\", ans_lab)\n",
    "    mkdir(output_dir)\n",
    "    pred_lab = lab_ref_dict[fail_data.pred_lab[i]]\n",
    "    from_path = fail_data.path[i]\n",
    "    to_name = str(pred_lab) + \"_\" + os.path.basename(from_path)\n",
    "    to_path = os.path.join(output_dir, to_name)\n",
    "    shutil.copy(from_path, to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix (ans * pred)\n",
    "l = lab_ref.shape[0]\n",
    "\n",
    "nums = conf_mat.values.astype(float)\n",
    "prec = np.diag(nums)/nums.sum(axis=0)\n",
    "recall = np.diag(nums)/nums.sum(axis=1)\n",
    "\n",
    "conf_result = np.zeros((l+1, l+1))\n",
    "conf_result[:l, :l] = conf_mat.values\n",
    "conf_result[l,:l] = prec\n",
    "conf_result[:l,l] = recall\n",
    "conf_result = pd.DataFrame(conf_result)\n",
    "conf_result.columns =  list(lab_ref.name.values) + [\"recall\"]\n",
    "conf_result.index = list(lab_ref.name.values) + [\"precision\"]\n",
    "conf_result.to_csv(\"result/conf_mat.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
